{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python379jvsc74a57bd0cebd8a093ba9e1842b8344ce835a191c4fcdfa74a730a14bd663e11063514626",
   "display_name": "Python 3.7.9 64-bit ('grad_project': conda)"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 221,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "import tqdm\n",
    "import os\n",
    "import csv\n",
    "import cv2\n",
    "import numpy as np\n",
    "import os\n",
    "from random import shuffle\n",
    "from tqdm import tqdm\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "import tflearn\n",
    "from tflearn.layers.conv import conv_2d, max_pool_2d\n",
    "from tflearn.layers.core import input_data,dropout,fully_connected\n",
    "from tflearn.layers.estimator import regression\n",
    "from tensorflow.python.framework import ops\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_size = 224"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_data_autistic_file_path = 'train/train/autistic'\n",
    "training_data_not_autistic_file_path = 'train/train/non_autistic'\n",
    "testing_data_file_path = 'test'\n",
    "def create_training_and_validation_data(training_data_count,validation_data_count):\n",
    "    all_autistic_data= []\n",
    "    all_non_autistic_data=[]\n",
    "    training_data = []\n",
    "    validation_data = []\n",
    "    for img in tqdm(os.listdir(training_data_autistic_file_path)):\n",
    "        path = os.path.join(training_data_autistic_file_path, img)\n",
    "        image = cv2.imread(path, cv2.IMREAD_COLOR)\n",
    "        all_autistic_data.append([np.array(image)/255.0,1])\n",
    "    \n",
    "    for img in tqdm(os.listdir(training_data_not_autistic_file_path)):\n",
    "        path = os.path.join(training_data_not_autistic_file_path, img)\n",
    "        image = cv2.imread(path, cv2.IMREAD_COLOR)\n",
    "        all_non_autistic_data.append([np.array(image)/255.0,0])\n",
    "\n",
    "    full_data = all_autistic_data + all_non_autistic_data\n",
    "    print(len(full_data))\n",
    "    shuffle(full_data)\n",
    "\n",
    "    for i in range(training_data_count):\n",
    "        training_data.append(full_data[i])\n",
    "    for i in range(training_data_count,training_data_count+validation_data_count):\n",
    "        validation_data.append(full_data[i])\n",
    "\n",
    "    shuffle(training_data)\n",
    "    shuffle(validation_data)\n",
    "    return training_data,validation_data\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "100%|██████████| 1268/1268 [00:02<00:00, 485.11it/s]\n",
      "100%|██████████| 1268/1268 [00:02<00:00, 509.22it/s]2536\n",
      "\n"
     ]
    }
   ],
   "source": [
    "training_data,validation_data = create_training_and_validation_data(2056,480)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "training_features = np.array([i[0] for i in training_data]).reshape(-1,image_size,image_size,3)\n",
    "training_labels= [i[1] for i in training_data]\n",
    "training_labels = keras.utils.to_categorical(training_labels, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "metadata": {},
   "outputs": [],
   "source": [
    "validation_features = np.array([i[0] for i in validation_data]).reshape(-1,image_size,image_size,3)\n",
    "validation_labels= [i[1] for i in validation_data]\n",
    "validation_labels = keras.utils.to_categorical(validation_labels, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 234,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "WARNING:tensorflow:Please add `keras.layers.InputLayer` instead of `keras.Input` to Sequential model. `keras.Input` is intended to be used by Functional model.\n",
      "Model: \"sequential_10\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_24 (Conv2D)           (None, 220, 220, 32)      2432      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_24 (MaxPooling (None, 110, 110, 32)      0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_4 (Batch (None, 110, 110, 32)      128       \n",
      "_________________________________________________________________\n",
      "conv2d_25 (Conv2D)           (None, 106, 106, 64)      51264     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_25 (MaxPooling (None, 53, 53, 64)        0         \n",
      "_________________________________________________________________\n",
      "flatten_11 (Flatten)         (None, 179776)            0         \n",
      "_________________________________________________________________\n",
      "dropout_11 (Dropout)         (None, 179776)            0         \n",
      "_________________________________________________________________\n",
      "dense_10 (Dense)             (None, 2)                 359554    \n",
      "=================================================================\n",
      "Total params: 413,378\n",
      "Trainable params: 413,314\n",
      "Non-trainable params: 64\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = keras.Sequential(\n",
    "    [\n",
    "        keras.Input(shape=(224,224,3)),\n",
    "        layers.Conv2D(32, kernel_size=(5, 5), activation=\"relu\"),\n",
    "        layers.MaxPooling2D(pool_size=(2, 2)),\n",
    "        layers.BatchNormalization(),\n",
    "        layers.Conv2D(64, kernel_size=(5, 5), activation=\"relu\"),\n",
    "        layers.MaxPooling2D(pool_size=(2, 2)),\n",
    "        layers.Flatten(),\n",
    "        layers.Dropout(0.5),\n",
    "        layers.Dense(2, activation=\"sigmoid\"),\n",
    "    ]\n",
    ")\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 235,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Train on 1850 samples, validate on 206 samples\n",
      "Epoch 1/15\n"
     ]
    }
   ],
   "source": [
    "batch_size = 256\n",
    "epochs = 15\n",
    "\n",
    "model.compile(loss=\"categorical_crossentropy\", optimizer=\"adam\", metrics=[\"accuracy\"])\n",
    "\n",
    "model.fit(training_features, training_labels, batch_size=batch_size, epochs=epochs, validation_split=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "score = model.evaluate(validation_features, validation_labels, verbose=0)\n",
    "print(\"Test loss:\", score[0])\n",
    "print(\"Test accuracy:\", score[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}